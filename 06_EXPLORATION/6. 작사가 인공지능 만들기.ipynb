{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 목차\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li style = \"margin-bottom:30px; list-style: none;\"><i style = \"font-weight:bold;font-style: normal;\">구글 드라이브 mount하여 연동하기</i></li>\n",
    "    <li style = \"margin-bottom:30px; list-style: none;\"><i style = \"font-weight:bold;font-style: normal;\">필요한 모듈 불러오기</i></li>\n",
    "    <li style = \"margin-bottom:30px; list-style: none;\"><i style = \"font-weight:bold;font-style: normal;\"><span style = \"font-weight:bold;color:#0172d4;\">STEP 1</span> : 데이터 읽어오기</i></li>\n",
    "    <li style = \"margin-bottom:30px; list-style: none;\"><i style = \"font-weight:bold;font-style: normal;\"><span style = \"font-weight:bold;color:#0172d4;\">STEP 2</span> : 데이터 정제</i></li>\n",
    "    <li style = \"margin-bottom:30px; list-style: none;\"><i style = \"font-weight:bold;font-style: normal;\"><span style = \"font-weight:bold;color:#0172d4;\">STEP 3</span> : 데이터를 Tensor로 변환하기</i></li>\n",
    "    <li style = \"margin-bottom:30px; list-style: none;\"><i style = \"font-weight:bold;font-style: normal;\"><span style = \"font-weight:bold;color:#0172d4;\">STEP 4</span> : 평가 데이터셋 분리</i>\n",
    "        <ul style = \"margin-top:10px; list-style:none;\">\n",
    "            <li style = \"margin-bottom:3px;\"><span style = \"font-weight:bold;color:#0172d4;\">1. </span> 생성된 텐서를 소스와 타겟으로 분리하기</li>\n",
    "            <li style = \"margin-bottom:5px;\"><span style = \"font-weight:bold;color:#0172d4;\">2. </span> 훈련 데이터와 평가 데이터를 분리하기</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li style = \"margin-bottom:30px; list-style: none;\"><i style = \"font-weight:bold;font-style: normal;\"><span style = \"font-weight:bold;color:#0172d4;\">STEP 5</span> : 인공지능 만들기</i>\n",
    "        <ul style = \"margin-top:10px; list-style:none;\">\n",
    "            <li style = \"margin-bottom:3px;\"><span style = \"font-weight:bold;color:#0172d4;\">1. </span> loss 지정하기</li>\n",
    "            <li style = \"margin-bottom:5px;\"><span style = \"font-weight:bold;color:#0172d4;\">2. </span> 텍스트 생성 클래스 선언하기</li>\n",
    "            <li style = \"margin-bottom:5px;\"><span style = \"font-weight:bold;color:#0172d4;\">3. </span> Model Build</li>\n",
    "            <li style = \"margin-bottom:5px;\"><span style = \"font-weight:bold;color:#0172d4;\">4. </span> Model 훈련하기</li>\n",
    "            <li style = \"margin-bottom:5px;\"><span style = \"font-weight:bold;color:#0172d4;\">5. </span> 작문을 통해 모델 평가해보기</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li style = \"margin-bottom:30px; list-style: none;\"><i style = \"font-weight:bold;font-style: normal;\">회고</i>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구글 드라이브 mount하여 연동하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2603,
     "status": "ok",
     "timestamp": 1652928417428,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "17-oXrZhP4yi",
    "outputId": "fcf094a3-e35e-4b28-a367-f793735bff80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요한 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1652928432535,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "VCY30VV9P1u9"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import glob\n",
    "import os, re\n",
    "\n",
    "import tensorflow        as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kk-OFNMe-XW"
   },
   "source": [
    "<div style = \"height: 50px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style = \"font-weight:bold;color:#0172d4;\">STEP 1</span> : 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12500,
     "status": "ok",
     "timestamp": 1652928563248,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "Qn_dqjTek_TJ",
    "outputId": "ebda2426-b17e-4c46-be06-2d5881b110be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/data/beatles.txt\n",
      "<class 'list'>\n",
      "\n",
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['Yesterday, all my troubles seemed so far away', \"Now it looks as though they're here to stay\", \"Oh, I believe in yesterday Suddenly, I'm not half the man I used to be\"]\n"
     ]
    }
   ],
   "source": [
    "txt_file_path = \"/content/drive/MyDrive/data/*\"\n",
    "txt_list = glob.glob(txt_file_path, recursive = False)\n",
    "print(txt_list[0])\n",
    "print(type(txt_list))\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"\\n데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style = \"font-weight:bold;color:#0172d4;\">STEP 2</span> : 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"font-size:15px; line-height:24px;\"> - preprocess_sentence() 사용하여 데이터 정제하기</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1652928582906,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "PJtTwYUiQM5j"
   },
   "outputs": [],
   "source": [
    "# 문장 필터링하기\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 25px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 정제하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2136,
     "status": "ok",
     "timestamp": 1652928586217,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "p8B-jNzlQXKe"
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
    "    if len(sentence) == 0: \n",
    "        continue\n",
    "    \n",
    "    if sentence[-1] == \":\": \n",
    "        continue\n",
    "    \n",
    "    # 토큰의 개수 15개 초과 시, 삭제\n",
    "    if len(sentence.split(' ')) >17:\n",
    "        continue\n",
    "        \n",
    "    # 정제를 하고 담아주세요tokenizer.num_words\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 25px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정제된 데이터 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1652928586217,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "JaLYkMaNQaL8",
    "outputId": "9d5e9760-7e98-4d35-9db4-1883dccab04d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> yesterday , all my troubles seemed so far away <end>',\n",
       " '<start> now it looks as though they re here to stay <end>',\n",
       " '<start> oh , i believe in yesterday suddenly , i m not half the man i used to be <end>',\n",
       " '<start> there s a shadow hanging over me . <end>',\n",
       " '<start> oh , yesterday came suddenly why she had to go i don t know she wouldn t say <end>',\n",
       " '<start> now i need a place to hide away <end>',\n",
       " '<start> oh , i believe in yesterday why she had to go i don t know she wouldn t say <end>',\n",
       " '<start> now i need a place to hide away <end>',\n",
       " '<start> oh , i believe in yesterday <end>',\n",
       " '<start> speaking words of wisdom , let it be <end>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정제된 결과를 10개만 확인\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style = \"font-weight:bold;color:#0172d4;\">STEP 3</span> : 데이터를 Tensor로 변환하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1652928586217,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "1IprZDURQcXB"
   },
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=12000, \n",
    "    filters=' ',\n",
    "    oov_token=\"<unk>\")\n",
    "    \n",
    "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
    "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 25px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3273,
     "status": "ok",
     "timestamp": 1652928589487,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "C0k6GVxnQfjr",
    "outputId": "c7551f6a-a7c3-49ef-c3c5-069d6009353a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2 888   4 ...   0   0   0]\n",
      " [  2  50  11 ...   0   0   0]\n",
      " [  2  41   4 ...   0   0   0]\n",
      " ...\n",
      " [  2 231   1 ...   0   0   0]\n",
      " [  2  10 501 ...   0   0   0]\n",
      " [  2 126  20 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7f4450e5f750>\n"
     ]
    }
   ],
   "source": [
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1652928589488,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "m8GM6mOJQpGF",
    "outputId": "963ede1f-a788-4641-d879-715b1fb8622a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2  888    4   25   13 2583 2021   30  356  137]\n",
      " [   2   50   11  776   81  322   43   53   93   10]\n",
      " [   2   41    4    5  213   14  888 2316    4    5]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[:3, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style = \"font-weight:bold;color:#0172d4;\">STEP 4</span> : 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 생성된 텐서를 소스와 타겟으로 분리하기\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1652928589488,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "FNwsvpQXQqyj",
    "outputId": "69cab03b-1e32-4f6c-ce62-fbd51c2e40d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2  888    4   25   13 2583 2021   30  356  137    3    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "[ 888    4   25   13 2583 2021   30  356  137    3    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성\n",
    "src_input = tensor[:, :-1] \n",
    "\n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성\n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 25px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분리된 데이터 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1652928589489,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "bJb7IJd5hjJi",
    "outputId": "d28a4864-3bdd-4ffe-a52e-4e1e819c43c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2, 888,   4, ...,   0,   0,   0],\n",
       "       [  2,  50,  11, ...,   0,   0,   0],\n",
       "       [  2,  41,   4, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  2, 231,   1, ...,   0,   0,   0],\n",
       "       [  2,  10, 501, ...,   0,   0,   0],\n",
       "       [  2, 126,  20, ...,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 훈련 데이터와 평가 데이터를 분리하기\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split() 함수 사용하여 훈련 데이터와 검증 데이터 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1652928589489,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "Ea7QCJG6SR9I"
   },
   "outputs": [],
   "source": [
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 25px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from_tensor_slices() 메소드를 이용해 훈련 데이터 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1652928589490,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "--P0y9RQWTE_"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(enc_train)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(enc_train) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4205,
     "status": "ok",
     "timestamp": 1652928593688,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "NYd5JJFAV8X9",
    "outputId": "9cf9be5c-d13b-4145-852b-612e44f7f648"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(256, 32), dtype=tf.int32, name=None), TensorSpec(shape=(256, 32), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from_tensor_slices() 메소드를 이용해 tf.data.Dataset객체를 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder = True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style = \"font-weight:bold;color:#0172d4;\">STEP 5</span> : 인공지능 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. loss 지정하기\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1652928593689,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "mk2VHOW6SwZV"
   },
   "outputs": [],
   "source": [
    "#Loss\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 텍스트 생성 클래스 선언하기\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1652928593690,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "F6xkworYS6aN"
   },
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Build\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1652928593690,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "m8y7FnHBTBnl"
   },
   "outputs": [],
   "source": [
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "error",
     "timestamp": 1652928593690,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "TGRYVMmoTDSe",
    "outputId": "899b1b75-c60a-4b8d-9160-b3de8e02a8e9"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[1;32m   2774\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m       raise ValueError(\n\u001b[0;32m-> 2776\u001b[0;31m           \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2777\u001b[0m           \u001b[0;34m'Build the model first by calling `build()` or by calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m           'the model on a batch of data.')\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAYkWFJ4T2sl"
   },
   "source": [
    "<p style= \"font-size:15px; line-height:24px;\">모델이 빌드되지 않은 상태에서 summary를 진행했기 때문에, 모델이 무슨 일을 하는 모델인지 알려주지 못한다. 따라서, 모델을 build하기 위해서는 어떤 데이터를 입력받아야하는지 알려줘야 하므로 데이터를(소스 데이터 = 특성값 = x값)을 모델에 넣어야한다.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 25px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터를 모델에 넣어주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6459,
     "status": "ok",
     "timestamp": 1652928603225,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "WMJ79VvTUt68",
    "outputId": "e6b70768-eb99-4e50-8357-426dae940226",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 32, 12001), dtype=float32, numpy=\n",
       "array([[[ 2.27355864e-04,  8.57987397e-05,  8.42949084e-05, ...,\n",
       "          4.07271524e-04,  1.49766100e-04, -5.81003369e-05],\n",
       "        [ 2.20872520e-04,  1.59759365e-05, -1.37129218e-05, ...,\n",
       "          4.17082891e-04,  1.19816192e-04, -8.72928795e-05],\n",
       "        [ 4.34078247e-04, -9.07997819e-05, -3.21990054e-04, ...,\n",
       "          5.20239351e-04, -2.94688594e-04, -2.74416292e-04],\n",
       "        ...,\n",
       "        [ 3.56825884e-03,  2.75751832e-03,  1.23283477e-04, ...,\n",
       "         -1.38996949e-03,  1.51385757e-04,  1.35969964e-03],\n",
       "        [ 3.59382806e-03,  2.77332682e-03,  1.33903537e-04, ...,\n",
       "         -1.40085595e-03,  1.67417311e-04,  1.35435676e-03],\n",
       "        [ 3.61532182e-03,  2.78613600e-03,  1.44411970e-04, ...,\n",
       "         -1.40862446e-03,  1.83653945e-04,  1.34916173e-03]],\n",
       "\n",
       "       [[ 2.27355864e-04,  8.57987397e-05,  8.42949084e-05, ...,\n",
       "          4.07271524e-04,  1.49766100e-04, -5.81003369e-05],\n",
       "        [ 4.22416982e-04, -9.81055709e-05, -4.30355394e-05, ...,\n",
       "          8.40737252e-04, -7.13620830e-05, -1.22174053e-04],\n",
       "        [ 4.49480402e-04, -4.93643747e-04, -2.98948289e-04, ...,\n",
       "          9.04599379e-04, -3.91930844e-05, -1.85769910e-04],\n",
       "        ...,\n",
       "        [ 3.51617532e-03,  2.59901420e-03,  2.72733072e-04, ...,\n",
       "         -1.28298369e-03, -3.49303882e-05,  1.51046121e-03],\n",
       "        [ 3.54444608e-03,  2.65791058e-03,  2.57647829e-04, ...,\n",
       "         -1.30740635e-03, -7.53603126e-06,  1.48670119e-03],\n",
       "        [ 3.56846140e-03,  2.70435307e-03,  2.46033276e-04, ...,\n",
       "         -1.32716226e-03,  2.08261772e-05,  1.46502699e-03]],\n",
       "\n",
       "       [[ 2.27355864e-04,  8.57987397e-05,  8.42949084e-05, ...,\n",
       "          4.07271524e-04,  1.49766100e-04, -5.81003369e-05],\n",
       "        [ 5.33049111e-04,  6.57750061e-05,  5.60151529e-05, ...,\n",
       "          3.86786414e-04,  3.92799382e-04,  9.91827765e-05],\n",
       "        [ 8.88416602e-04, -3.20361105e-05, -1.14596471e-04, ...,\n",
       "          1.34912669e-04,  5.43538132e-04, -4.43740100e-05],\n",
       "        ...,\n",
       "        [ 3.60565726e-03,  2.67457729e-03,  1.48527208e-04, ...,\n",
       "         -1.33318116e-03,  2.35206360e-04,  1.46833796e-03],\n",
       "        [ 3.62509605e-03,  2.70401430e-03,  1.56760303e-04, ...,\n",
       "         -1.35462207e-03,  2.37050728e-04,  1.44806784e-03],\n",
       "        [ 3.64161539e-03,  2.72844825e-03,  1.65027916e-04, ...,\n",
       "         -1.37116970e-03,  2.40999027e-04,  1.42974360e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.27355864e-04,  8.57987397e-05,  8.42949084e-05, ...,\n",
       "          4.07271524e-04,  1.49766100e-04, -5.81003369e-05],\n",
       "        [ 1.22732614e-04,  1.62497206e-04,  2.45607167e-04, ...,\n",
       "          3.35416116e-04,  2.75137165e-04, -3.16321857e-05],\n",
       "        [-3.03234614e-04,  2.17725843e-04,  1.92893989e-04, ...,\n",
       "          2.38265508e-04,  2.87663628e-04, -1.37024224e-04],\n",
       "        ...,\n",
       "        [ 3.48669267e-03,  2.63674883e-03,  2.97209568e-04, ...,\n",
       "         -1.17919804e-03,  1.34430680e-04,  1.50237698e-03],\n",
       "        [ 3.52128572e-03,  2.68096267e-03,  2.75165861e-04, ...,\n",
       "         -1.22063584e-03,  1.39869167e-04,  1.48596568e-03],\n",
       "        [ 3.55136744e-03,  2.71639624e-03,  2.58147280e-04, ...,\n",
       "         -1.25591957e-03,  1.47654282e-04,  1.46957068e-03]],\n",
       "\n",
       "       [[ 2.27355864e-04,  8.57987397e-05,  8.42949084e-05, ...,\n",
       "          4.07271524e-04,  1.49766100e-04, -5.81003369e-05],\n",
       "        [ 1.36359478e-04, -3.79250014e-05,  1.88850172e-04, ...,\n",
       "          6.60470047e-04,  1.10504916e-04, -2.47621880e-04],\n",
       "        [-1.48841660e-04, -2.46041309e-04,  3.54973349e-06, ...,\n",
       "          8.31437996e-04,  1.11424430e-04, -5.26538759e-04],\n",
       "        ...,\n",
       "        [ 3.62532330e-03,  2.76175351e-03,  1.40742181e-04, ...,\n",
       "         -1.31408812e-03,  1.58310635e-04,  1.40378217e-03],\n",
       "        [ 3.64094716e-03,  2.78109149e-03,  1.50556938e-04, ...,\n",
       "         -1.33193482e-03,  1.76857109e-04,  1.39094144e-03],\n",
       "        [ 3.65409628e-03,  2.79635959e-03,  1.59882155e-04, ...,\n",
       "         -1.34665985e-03,  1.94598004e-04,  1.37950771e-03]],\n",
       "\n",
       "       [[ 2.27355864e-04,  8.57987397e-05,  8.42949084e-05, ...,\n",
       "          4.07271524e-04,  1.49766100e-04, -5.81003369e-05],\n",
       "        [ 1.22732614e-04,  1.62497206e-04,  2.45607167e-04, ...,\n",
       "          3.35416116e-04,  2.75137165e-04, -3.16321857e-05],\n",
       "        [-1.37643496e-04, -8.29224700e-06,  2.72526027e-04, ...,\n",
       "          1.85860088e-04,  3.18665901e-04,  1.03992468e-04],\n",
       "        ...,\n",
       "        [ 3.48457624e-03,  2.65505584e-03,  1.92170584e-04, ...,\n",
       "         -1.30363693e-03,  4.70799132e-05,  1.46490615e-03],\n",
       "        [ 3.52186081e-03,  2.68464070e-03,  1.89774611e-04, ...,\n",
       "         -1.32557470e-03,  6.81916208e-05,  1.44610228e-03],\n",
       "        [ 3.55385756e-03,  2.70923343e-03,  1.89377810e-04, ...,\n",
       "         -1.34337659e-03,  9.03437031e-05,  1.42915593e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "<p style= \"font-size:15px; line-height:24px;\">모델이 빌드되지 않은 상태에서 summary를 진행했기 때문에, 모델이 무슨 일을 하는 모델인지 알려주지 못한다. 따라서, 모델을 build하기 위해서는 어떤 데이터를 입력받아야하는지 알려줘야 하므로 데이터를(소스 데이터 = 특성값 = x값)을 모델에 넣어야한다.</p>\n",
    "\n",
    "<div style = \"height: 25px;\"><div/>\n",
    "\n",
    "### 데이터를 모델에 넣어주기for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 25px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델의 정보 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1652928603225,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "D4WHk-WdVLkD",
    "outputId": "138e5323-a561-43a9-859a-0201fc50a03a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  3072256   \n",
      "                                                                 \n",
      " lstm (LSTM)                 multiple                  5246976   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               multiple                  8392704   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  12301025  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 이제 모델이 뭐하는지 알았으니 summary해서 모델의 정보 확인하기\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"font-size:15px; line-height:24px;\">모델의 파라미터가 29,012,961이 나왔다.<br/>\n",
    "따라서, 모델을 돌리는데에 있어 <span style = 'background-color:#fff5b1; padding:0.2px;'>시간이 오래 걸릴 것</span>이라고 예상된다.<br/>\n",
    "뿐만아니라, 파라미터가 많기 때문에 <span style = 'background-color:#fff5b1; padding:0.2px;'>과적합</span>이 발생할 수 있다는 문제가 발생할 수 있다고 생각한다.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model 훈련하기\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1181159,
     "status": "ok",
     "timestamp": 1652929784378,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "k6d_kuAcjVJ-",
    "outputId": "6812d48c-d109-4c23-8cd3-d5a32801bcb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "535/535 [==============================] - 121s 222ms/step - loss: 1.7351 - val_loss: 1.5025\n",
      "Epoch 2/10\n",
      "535/535 [==============================] - 118s 220ms/step - loss: 1.4493 - val_loss: 1.4212\n",
      "Epoch 3/10\n",
      "535/535 [==============================] - 118s 220ms/step - loss: 1.3718 - val_loss: 1.3655\n",
      "Epoch 4/10\n",
      "535/535 [==============================] - 118s 220ms/step - loss: 1.3105 - val_loss: 1.3225\n",
      "Epoch 5/10\n",
      "535/535 [==============================] - 118s 220ms/step - loss: 1.2583 - val_loss: 1.2916\n",
      "Epoch 6/10\n",
      "535/535 [==============================] - 118s 220ms/step - loss: 1.2117 - val_loss: 1.2653\n",
      "Epoch 7/10\n",
      "535/535 [==============================] - 118s 220ms/step - loss: 1.1696 - val_loss: 1.2437\n",
      "Epoch 8/10\n",
      "535/535 [==============================] - 118s 220ms/step - loss: 1.1303 - val_loss: 1.2259\n",
      "Epoch 9/10\n",
      "535/535 [==============================] - 118s 220ms/step - loss: 1.0937 - val_loss: 1.2103\n",
      "Epoch 10/10\n",
      "535/535 [==============================] - 118s 220ms/step - loss: 1.0592 - val_loss: 1.1972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f444f309110>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n",
    "\n",
    "model.compile(loss = loss, optimizer = optimizer)\n",
    "model.fit(dataset, validation_data = (enc_val, dec_val), epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"font-size:15px; line-height:24px;\">모델을 훈련시킨 시간은 <span style = 'background-color:#fff5b1; padding:0.2px;'>총 2시간 50분</span>이 걸렸다.<br/>\n",
    "예상한대로, 히든레이어와, 임베딩 사이즈를 크게 주었기 때문에 파라미터가 많이 생성되었고, 이로 인해 모델의 훈련 속도가 느려진 것 같다.\n",
    "loss값은 과적합 되었을 것이라는 예상과는 다르게, 훈련 데이터의 loss값과 검증 데이터셋의 loss값이 크게 차이가 나지 않으면서, <span style = 'background-color:#fff5b1; padding:0.2px;'>1.2 이하로 떨어졌다.</span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 작문을 통해 모델 평가해보기\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 작문 진행 함수 선언하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1652929784379,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "GCNLorft6-gb"
   },
   "outputs": [],
   "source": [
    "# 작문 진행 함수\n",
    "\n",
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "        \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 작문해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1652929784379,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "cX_iar25kU5k",
    "outputId": "fb283c6b-3edc-4bb3-c59f-eea8b26398c7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<start> always since i m a <unk> <end> '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> always\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1652929784379,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "jOzMFjrK8Gc0",
    "outputId": "4ff51805-29cb-4def-c280-f0033d746476"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<start> i think i m a bad bitch <end> '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i think\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1652929784380,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "rQfU-DnBC3wz",
    "outputId": "003bcb1a-1a4c-4ed3-c690-a5da8753e84c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<start> i want to be a little selfish <end> '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i want\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1652929784816,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "1HZOFK0bK6wl",
    "outputId": "2ce86cf7-094a-4936-fe3c-bc2309181338"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<start> please don t stop the music , i m a flirt <end> '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> please\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1652929784817,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "X4ETyv1mLCYL",
    "outputId": "990e2406-ee2e-40e6-db3c-3cedc4058bcd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<start> from the bottom of the night <end> '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> from\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1652929784817,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "II21LBbsLGIk",
    "outputId": "93522d29-e334-466e-f8ea-463a07f60f69"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<start> love is a little selfish <end> '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> love\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1652929784817,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "srU58cFhMzKV",
    "outputId": "7b9084d4-8c6b-4d51-931b-871b15228788"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<start> i love you , i love you <end> '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1652929784818,
     "user": {
      "displayName": "생크림와플먹고싶다",
      "userId": "13048533309979940862"
     },
     "user_tz": -540
    },
    "id": "fp9L2g2zM10u",
    "outputId": "d3e557a1-9b31-4572-98d9-16fe001634b2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<start> believe me , love me , love me , love me , love me , love me , love '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> believe\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aq_AcduPJluM"
   },
   "source": [
    "<p style= \"font-size:15px; line-height:24px;\">대부분 잘 나온 것을 확인할 수 있었다. 그런데 도서관 사서를 많이 사랑하나보다.<br/> 취향이 확고한 모델인 것 같다.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"><div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회고\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"font-size:16px; line-height:30px;\">이번 프로젝트를 하면서 처음으로 코랩 pro를 사용해보았는데, 평소 사용하던 jupyter notebook과는 사용 방법이 많이 달라 사용하는데 애를 많이 먹었습니다.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 코랩에서 파일을 불러오기 위해서는 구글 드라이브에 올려 불러오는 것이 편하다.\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"font-size:16px; line-height:30px;\">로컬 파일을 불러오고자 경로 설정을 하였는데 되지 않아 확인해본 결과,</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"font-size:16px; line-height:30px;\">를 통해 구글 드라이브와 연동을 시킨 후 파일을 불러올 수 있었다.<br/>\n",
    "또한, 이때 기본 주소(HOME)는 content/가 되며, 이는 os.getcwd()를 통해 현재 경로를 확인할 수 있다.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 드라이브 상의 파일의 경로 확인하기\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"img/colab_01.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"font-size:16px; line-height:30px;\">왼쪽 파일 아이콘을 눌러 폴더 목록을 열은 후 원하는 파일에 오른쪽 클릭을 하여 경로를 복사할 수 있다.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델을 fit할 때에는 꼭 변수를 지정하자\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"font-size:16px; line-height:30px;\">모델의 훈련 과정과 데이터의 loss값 등을 이용하기 위해서는 model.fit()할 때, </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"font-size:16px; line-height:30px;\">이렇게 변수를 지정하여 값을 저장해야, 후에 loss값 비교, 모델별 성능 비교 등을 할 수 있으므로, <span style = 'background-color:#fff5b1; padding:0.2px;'>반드시 변수를 생성하는 것이 좋다.</span> <br/>\n",
    "모델을 모두 학습시키고 난 후, 이 사실을 알게되어서 매우 슬펐다. <br/>\n",
    "이번에 모델을 돌릴 때에는 시간이 많이 소요됐으므로 넘어가고, 다음에는 반드시 변수에 저장하여 사용할 것이다.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 서브 클래스를 사용하여 모델을 설계했을 때에는 tf.keras.callbacks.ModelCheckpoint로 저장하자\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [콜백 사용하는 방법 1](https://deep-deep-deep.tistory.com/53)\n",
    "- [콜백 사용하는 방법 2](https://teddylee777.github.io/tensorflow/keras-%EC%BD%9C%EB%B0%B1%ED%95%A8%EC%88%98-vol-02)\n",
    "- [텐서플로우 콜백](https://www.tensorflow.org/guide/checkpoint?hl=ko)\n",
    "- [model.save()](https://www.tensorflow.org/guide/keras/save_and_serialize?hl=ko)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"font-size:16px; line-height:30px;\">파일을 닫고 다시 열었을 때에는 모델을 다시 사용할 수 없으므로, model.save()를 사용하여 .h5(h5파일)로 저장해야한다. 이 후, tf.saved_model.load()로 쉽게 불러올 수 있다.<br/>\n",
    "<span style = 'background-color:#fff5b1; padding:0.2px;'>그러나, 이 방법은 함수형 또는 시퀀셜 API(모델을 순차적으로 쌓음)를 사용하여 만든 모델에만 사용하 가능하다.</span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"font-size:16px; line-height:30px;\">실제로 모델을 돌렸을 시,  save_format='tf'으로 지정하라는 오류가 발생하는 것을 확인할 수 있었다.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"font-size:16px; line-height:30px;\">이 후, 모델을 tf로 저장하여 불러오니, model.summary()는 먹히나, 모델 입력 값의 shape가 다르다는 오류가 발생하였다.\n",
    "확인해본 결과, model.save()는 서브클래스를 사용한 모델은 저장할 수 없으며, 가중치만 저장하여 사용할 수 있다는 것을 확인할 수 있었다. <br/>\n",
    "때문에, 파일로 저장된 모델과 실제 적용하는 모델이 달라져서 적용할 수 없었다.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"font-size:16px; line-height:30px;\">서브 클래스를 사용하여 모델을 설계했다면, <span style = 'background-color:#fff5b1; padding:0.2px;'>tf.keras.callbacks.ModelCheckpoint</span>로 모델의 저장하여 불러올 수 있다.<br/>\n",
    "ModelCheckpoint는 모델이 학습하면서 정의한 조건(fit())을 만족했을 때, Model의 가중치 값을 중간중간 저장한다. 학습시간이 오래 걸린다면 loss값이 올라갔을 때에는 저장하지 않고, 떨어졌을 때에는 가중치를 저장함으로서, 중간에 과적합이 발생하였거나, 다양한 문제가 발생했을 때, 다시 중간의 가중치 값을 불러와서 학습을 이어나갈 수 있다.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"height: 50px;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 코랩은 모델을 fit()하는 도중, 시간이 지나면 런타임이 끊긴다.  \n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style= \"font-size:16px; line-height:30px;\">이번에는 모델의 훈련 시간이 오래 걸리기 때문에, 자기 직전 model.fit()을 실행시켰다.\n",
    "자고 일어나면 모델 훈련이 끝났을 것이라는 기대와는 달리, 중간에 런타임이 끊겨 모델을 다시 사용할 수도 없고, 훈련 도중에 런타임이 끊긴 것을 확인할 수 있었다.<br/>\n",
    "조심하여 돌려야겠다.</p>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNa/q+KFsKQhFgj9O7jnpXh",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
